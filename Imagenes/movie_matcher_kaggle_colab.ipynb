{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d361a83",
   "metadata": {},
   "source": [
    "# MovieMatcher — Notebook Colab\n",
    "\n",
    "**Objetivo:** entrenar un modelo compacto (distilgpt2) con el dataset *Wikipedia Movie Plots* (Kaggle) para generar recomendaciones y tramas similares a partir de una descripción del usuario.\n",
    "\n",
    "**Instrucciones rápidas:**\n",
    "\n",
    "1. Sube tu `kaggle.json` (API token) usando el icono de archivos en Colab o ejecuta la celda de upload.\n",
    "\n",
    "2. Ejecuta las celdas en orden. Ajusta `N_EXAMPLES` y `NUM_EPOCHS` según recursos de Colab.\n",
    "\n",
    "> Nota: el entrenamiento puede consumir recursos. Para demo rápido, usa `N_EXAMPLES = 500` y `NUM_EPOCHS = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) Instalar dependencias (ejecutar)\n",
    "# Si ya tienes torch instalado con GPU, puedes ajustar la instalación de torch apropiada.\n",
    "!pip install -q transformers datasets gradio kaggle pandas sentencepiece torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) Subir kaggle.json (si no lo has subido manualmente)\n",
    "from google.colab import files\n",
    "print('Si ya subiste ~/.kaggle/kaggle.json omite este paso.')\n",
    "uploaded = files.upload()\n",
    "print('Archivos subidos:', list(uploaded.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223bacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3) Configurar Kaggle (si subiste kaggle.json)\n",
    "import os\n",
    "if os.path.exists('kaggle.json'):\n",
    "    os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
    "    !cp kaggle.json ~/.kaggle/kaggle.json\n",
    "    !chmod 600 ~/.kaggle/kaggle.json\n",
    "    print('kaggle.json copiado a ~/.kaggle/kaggle.json') \n",
    "else:\n",
    "    print('No se encontró kaggle.json en el directorio actual. Si lo subiste con el diálogo, recarga el kernel.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e597db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4) Descargar dataset Wikipedia Movie Plots desde Kaggle\n",
    "# Dataset: jrobischon/wikipedia-movie-plots\n",
    "!kaggle datasets download -d jrobischon/wikipedia-movie-plots -p /content --unzip -q\n",
    "import os\n",
    "print('Archivos en /content:', os.listdir('/content')[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) Cargar y explorar el dataset con pandas\n",
    "import pandas as pd\n",
    "import os\n",
    "csv_path = '/content/wiki_movie_plots_deduped.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    files = os.listdir('/content')\n",
    "    candidates = [f for f in files if f.endswith('.csv')]\n",
    "    if len(candidates) > 0:\n",
    "        csv_path = os.path.join('/content', candidates[0])\n",
    "    else:\n",
    "        raise FileNotFoundError('No se encontró el CSV del dataset. Asegúrate de que la descarga/zip funcionó.')\n",
    "print('Usando:', csv_path)\n",
    "df = pd.read_csv(csv_path)\n",
    "print('Tamaño del dataset:', len(df))\n",
    "df = df.dropna(subset=['Plot', 'Title'])\n",
    "df = df.reset_index(drop=True)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6cc6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6) Preprocesamiento básico\n",
    "import re\n",
    "def limpiar_texto(t):\n",
    "    t = str(t)\n",
    "    t = re.sub(r'\\\\s+', ' ', t)\n",
    "    t = re.sub(r'\\[[^\\]]*\\]', '', t)\n",
    "    return t.strip()\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "df['Plot_clean'] = df['Plot'].apply(limpiar_texto)\n",
    "df['plot_len'] = df['Plot_clean'].str.split().apply(len)\n",
    "print('longitud media (palabras):', int(df['plot_len'].mean()))\n",
    "df = df[(df['plot_len'] >= 20) & (df['plot_len'] <= 800)].reset_index(drop=True)\n",
    "print('Después de filtrar por longitud:', len(df))\n",
    "df[['Title','Plot_clean']].sample(3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c547c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7) Construir pares Prompt -> Recomendación (titles) y Prompt -> Sinopsis (opcional)\n",
    "N_EXAMPLES = 2000  # Ajusta para Colab gratuito: prueba con 500 o 1000\n",
    "df_small = df.sample(n=min(N_EXAMPLES, len(df)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "pairs = []\n",
    "for idx, row in df_small.iterrows():\n",
    "    words = row['Plot_clean'].split()\n",
    "    prompt = ' '.join(words[:35])\n",
    "    title = row['Title']\n",
    "    short_plot = ' '.join(words[:70])\n",
    "    pairs.append({'prompt': prompt, 'target_title': title, 'target_plot': short_plot})\n",
    "\n",
    "import pandas as pd\n",
    "pairs_df = pd.DataFrame(pairs)\n",
    "print('Ejemplos de pares:')\n",
    "pairs_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c26dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8) Construir dataset de entrenamiento en formato Hugging Face\n",
    "from datasets import Dataset\n",
    "MODE = 'title'  # 'title' o 'plot'\n",
    "\n",
    "if MODE == 'title':\n",
    "    hf_examples = [{'text': f'Prompt: {r[\"prompt\"]}  Recomendacion:' + ' ' + r['target_title']} for _, r in pairs_df.iterrows()]\n",
    "else:\n",
    "    hf_examples = [{'text': f'Prompt: {r[\"prompt\"]}  Sinopsis:' + ' ' + r['target_plot']} for _, r in pairs_df.iterrows()]\n",
    "\n",
    "ds = Dataset.from_list(hf_examples)\n",
    "print('Dataset HF creado. Ejemplos:')\n",
    "ds.select(range(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8848926",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9) Tokenizador y modelo (distilgpt2) — preparar pad token y resize embeddings\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_ID = 'distilgpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "tokenizer.pad_token = tokenizer.pad_token or tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.get('pad_token_id', tokenizer.convert_tokens_to_ids(tokenizer.pad_token))\n",
    "\n",
    "print('Vocab size:', len(tokenizer))\n",
    "print('Modelo y tokenizer listos.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10) Tokenizar y crear labels (labels = input_ids) para causal LM\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "def tokenize_and_label(batch):\n",
    "    toks = tokenizer(batch['text'], truncation=True, padding='max_length', max_length=MAX_LENGTH)\n",
    "    toks['labels'] = toks['input_ids'].copy()\n",
    "    return toks\n",
    "\n",
    "print('Tokenizando dataset... (esto puede tardar unos minutos según N_EXAMPLES)')\n",
    "ds_tok = ds.map(tokenize_and_label, batched=True, remove_columns=['text'])\n",
    "print(ds_tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11) Preparar Trainer y TrainingArguments\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "NUM_EPOCHS = 1  # aumentar si tienes recursos\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./movie_matcher_model',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=50,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_tok,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "print('Trainer listo. Para entrenar ejecuta trainer.train()')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 12) Entrenar el modelo (descomenta para ejecutar)\n",
    "# Atención: en Colab gratuito el entrenamiento puede tardar y consumir memoria.\n",
    "# Si quieres probar rápido, reduce N_EXAMPLES y NUM_EPOCHS arriba.\n",
    "# trainer.train()\n",
    "# trainer.save_model('./movie_matcher_model')\n",
    "print('Si quieres entrenar, descomenta trainer.train() y trainer.save_model(...) en esta celda.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318790cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 13) Función para generar recomendaciones (usa el modelo cargado en memoria)\n",
    "import torch\n",
    "\n",
    "def generar_recomendacion(prompt, max_length=80, temperature=1.0, top_p=0.92, top_k=50, repetition_penalty=1.8, no_repeat_ngram_size=3):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        entrada = f'Prompt: {prompt}  Recomendacion:'\n",
    "        inputs = tokenizer(entrada, return_tensors='pt')\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return text.replace(entrada, '').strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 14) Interfaz Gradio para probar (ejecuta esta celda después de entrenar o si cargas un modelo guardado)\n",
    "import gradio as gr\n",
    "\n",
    "def gradio_fn(prompt, max_length, temp, top_p, top_k, rep_penalty, no_repeat):\n",
    "    return generar_recomendacion(prompt, max_length=int(max_length), temperature=float(temp), top_p=float(top_p), top_k=int(top_k), repetition_penalty=float(rep_penalty), no_repeat_ngram_size=int(no_repeat))\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_fn,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, label='Describe lo que quieres ver'),\n",
    "        gr.Slider(20, 200, value=80, label='max_length'),\n",
    "        gr.Slider(0.1, 2.0, value=1.0, label='temperature'),\n",
    "        gr.Slider(0.1, 1.0, value=0.92, label='top_p'),\n",
    "        gr.Slider(1, 200, value=50, step=1, label='top_k'),\n",
    "        gr.Slider(1.0, 3.0, value=1.8, step=0.1, label='repetition_penalty'),\n",
    "        gr.Slider(1, 5, value=3, step=1, label='no_repeat_ngram_size'),\n",
    "    ],\n",
    "    outputs=gr.Textbox(label='Recomendación / Texto generado'),\n",
    "    title='MovieMatcher - Recomendador de películas (demo)',\n",
    "    description='Introduce una breve descripción y el modelo sugerirá títulos o tramas (según el modo).'\n",
    ")\n",
    "\n",
    "# Lanza la interfaz (en Colab mostrará un enlace público)\n",
    "iface.launch(enable_queue=True, share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f524346d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Notas finales\n",
    "\n",
    "- Ajusta `MODE`, `N_EXAMPLES`, `NUM_EPOCHS`, `MAX_LENGTH` y `BATCH_SIZE` según los recursos de Colab.\n",
    "- Para una demo rápida: `MODE='title'`, `N_EXAMPLES=500`, `NUM_EPOCHS=1`, `BATCH_SIZE=2`.\n",
    "- Si vas a publicar el modelo, recuerda citar el dataset de Kaggle y respetar licencias.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
