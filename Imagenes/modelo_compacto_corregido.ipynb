{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911c9f0e",
   "metadata": {},
   "source": [
    "# üß† Modelo Compacto de Lenguaje con Wikipedia y DistilGPT-2\n",
    "Este notebook entrena un modelo de lenguaje peque√±o basado en `distilgpt2` utilizando art√≠culos de Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Instalaci√≥n de dependencias\n",
    "!pip install transformers datasets gradio wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0505b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: Importaci√≥n de librer√≠as necesarias\n",
    "import wikipedia\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling)\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f70733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Recolecci√≥n de datos desde Wikipedia\n",
    "def recolectar_articulos(tema, num_articulos=5):\n",
    "    wikipedia.set_lang(\"es\")\n",
    "    articulos = []\n",
    "    titulos = wikipedia.search(tema, results=num_articulos)\n",
    "    for titulo in titulos:\n",
    "        try:\n",
    "            contenido = wikipedia.page(titulo).content\n",
    "            articulos.append(contenido)\n",
    "        except:\n",
    "            continue\n",
    "    return articulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Preprocesamiento b√°sico del texto\n",
    "def limpiar_texto(texto):\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    texto = re.sub(r'\\[[^\\]]*\\]', '', texto)\n",
    "    texto = re.sub(r'==.*?==', '', texto)\n",
    "    return texto.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae76b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5: Descargar y limpiar art√≠culos\n",
    "articulos = recolectar_articulos(\"inteligencia artificial\", num_articulos=5)\n",
    "print(f\"Se descargaron {len(articulos)} art√≠culos.\")\n",
    "\n",
    "textos_limpios = [limpiar_texto(t) for t in articulos]\n",
    "textos_entrenamiento = textos_limpios\n",
    "print(f\"Se limpiaron {len(textos_entrenamiento)} textos para el entrenamiento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a15b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 6: Cargar el modelo preentrenado y corregir token de padding\n",
    "modelo_id = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo_id)\n",
    "modelo = AutoModelForCausalLM.from_pretrained(modelo_id)\n",
    "\n",
    "# Soluci√≥n al error de padding\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "modelo.config.pad_token_id = modelo.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fedc008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 7: Entrenamiento del modelo (fine-tuning)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": textos_entrenamiento})\n",
    "\n",
    "argumentos_entrenamiento = TrainingArguments(\n",
    "    output_dir=\"./modelo_compacto\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "entrenador = Trainer(\n",
    "    model=modelo,\n",
    "    args=argumentos_entrenamiento,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset\n",
    ")\n",
    "\n",
    "entrenador.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1aae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 8: Crear interfaz con Gradio para probar el modelo\n",
    "def responder(prompt):\n",
    "    entradas = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    salida = modelo.generate(**entradas, max_new_tokens=50)\n",
    "    return tokenizer.decode(salida[0], skip_special_tokens=True)\n",
    "\n",
    "iface = gr.Interface(fn=responder, inputs=\"text\", outputs=\"text\", title=\"Modelo Compacto de Lenguaje\")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5551b91",
   "metadata": {},
   "source": [
    "‚úÖ **Listo:** ahora podr√°s probar el modelo escribiendo una frase en la interfaz de Gradio que se abrir√° al final."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
